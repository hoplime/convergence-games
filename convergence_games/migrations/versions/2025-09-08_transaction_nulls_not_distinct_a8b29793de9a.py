"""Transaction nulls not distinct

Revision ID: a8b29793de9a
Revises: bb8d9e0cab15
Create Date: 2025-09-08 14:32:14.854392

"""
# pyright: reportUnusedCallResult=false

import warnings
from typing import TYPE_CHECKING

import sqlalchemy as sa
from advanced_alchemy.types import (
    GUID,
    ORA_JSONB,
    DateTimeUTC,
    EncryptedString,
    EncryptedText,
    StoredObject,
)
from alembic import op
from sqlalchemy import Text  # noqa: F401

if TYPE_CHECKING:
    pass

__all__ = ["downgrade", "upgrade", "schema_upgrades", "schema_downgrades", "data_upgrades", "data_downgrades"]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB
sa.EncryptedString = EncryptedString
sa.EncryptedText = EncryptedText
sa.StoredObject = StoredObject

# revision identifiers, used by Alembic.
revision = "a8b29793de9a"
down_revision = "bb8d9e0cab15"
branch_labels = None
depends_on = None


def upgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()


def downgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()


def schema_upgrades() -> None:
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("user_event_compensation_transaction", schema=None) as batch_op:
        batch_op.drop_constraint("uq_compensation_transaction_event_user_previous", type_="unique")
        batch_op.create_unique_constraint(
            "uq_compensation_transaction_event_user_previous",
            ["event_id", "user_id", "previous_transaction_id"],
            postgresql_nulls_not_distinct=True,
        )

    with op.batch_alter_table("user_event_d20_transaction", schema=None) as batch_op:
        batch_op.drop_constraint("uq_d20_transaction_event_user_previous", type_="unique")
        batch_op.create_unique_constraint(
            "uq_d20_transaction_event_user_previous",
            ["event_id", "user_id", "previous_transaction_id"],
            postgresql_nulls_not_distinct=True,
        )

    # ### end Alembic commands ###


def schema_downgrades() -> None:
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("user_event_d20_transaction", schema=None) as batch_op:
        batch_op.drop_constraint("uq_d20_transaction_event_user_previous", type_="unique")
        batch_op.create_unique_constraint(
            "uq_d20_transaction_event_user_previous",
            ["event_id", "user_id", "previous_transaction_id"],
            postgresql_nulls_not_distinct=False,
        )

    with op.batch_alter_table("user_event_compensation_transaction", schema=None) as batch_op:
        batch_op.drop_constraint("uq_compensation_transaction_event_user_previous", type_="unique")
        batch_op.create_unique_constraint(
            "uq_compensation_transaction_event_user_previous",
            ["event_id", "user_id", "previous_transaction_id"],
            postgresql_nulls_not_distinct=False,
        )

    # ### end Alembic commands ###


def data_upgrades() -> None:
    """Add any optional data upgrade migrations here!"""


def data_downgrades() -> None:
    """Add any optional data downgrade migrations here!"""
